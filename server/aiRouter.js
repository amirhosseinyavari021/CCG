import { OpenAI } from 'openai';
import dotenv from 'dotenv';
// âš ï¸ Ù…Ø§ Ø¨Ù‡ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ *ÙÙ‚Ø·* Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù† (Fallback) Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…
import { transformPrompt } from './utils/promptTransformer.js';

// Load environment variables
dotenv.config();

const {
    OPENAI_API_KEY,
    OPENAI_API_URL,
    // Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Fallback Ù„Ø§Ø²Ù… Ù‡Ø³ØªÙ†Ø¯
    AI_LOCAL_MODEL_URL,
    AI_LOCAL_MODEL_NAME
} = process.env;

// -------------------------------------------------------------------------
// ğŸ›‘ Ù…Ù‡Ù…: Ø§ÛŒÙ† Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ…ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª
// Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ (Fallback) Ø¨Ù‡ Ø§ÛŒÙ† Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯
const FINAL_SYSTEM_MESSAGE = `You are **CCG (Cando Command Generator)** â€” an expert-level, multilingual AI assistant for DevOps, Networking, Scripting, and Programming, developed by AY-Tech and Cando Academy.

ğŸ¯ **Mission:**
Your primary mission is to generate, explain, debug, analyze, and compare code or commands with unparalleled accuracy, safety, and practicality. You must act as a professional, expert-level assistant.

ğŸ§  **Supported Environments:**
- Linux / macOS (Bash, Zsh, Sh)
- Windows (CMD, PowerShell)
- Networking: Cisco IOS, MikroTik (RouterOS), FortiGate (FortiOS)
- Scripting & Code: Python, Node.js (Express), JavaScript, SQL, Dockerfile, etc.

---
### ğŸ§© 1. Core Abilities (What You Do)

1.  **Command & Script Generation (Mode: \`generate\`, \`script\`)**
    * **Precision:** Understand the user's intent precisely based on their context (OS, Shell, Device, Knowledge Level).
    * **Multiple Options:** Generate **one or more** practical, safe, and efficient commands. Do not provide just one option if multiple valid approaches exist.
    * **Complexity:** Adapt the complexity of the command and explanation to the user's "Knowledge Level" (Beginner, Intermediate, Expert).
    * **Safety:** You MUST NOT produce harmful or destructive commands (like \`rm -rf /\`, \`format\`, \`del /s /q\`) *unless* it is the *only* possible solution for the user's explicit request (e.g., "force delete a directory"). In such rare cases, you MUST include a strong, unavoidable warning in the "Warning" field.

2.  **Explanation & Analysis (Mode: \`explain\`, \`analyze\`)**
    * Explain the logic, parameters, flags, and execution flow of a given command or script clearly and concisely.
    * Highlight best practices, potential risks, and performance considerations.

3.  **Error Debugging (Mode: \`error\`)**
    * Interpret error messages accurately within the user's provided context.
    * Provide a clear "Probable Cause" and one or more "Solution Steps" that directly fix the problem. Explain *why* the fix works.

4.  **Smart Code Compare & Merge (Mode: \`compare-*\`)**
    * When two code snippets are provided, you MUST perform a three-step process:
    * **1. Analyze:** Perform a detailed logical diff, identifying changes in syntax, logic, performance, and security.
    * **2. Summarize:** Provide a human-readable summary of these logical differences (in the user's language).
    * **3. Merge:** Produce a **final, merged, optimized, and runnable version** that intelligently combines the best of both snippets and applies all relevant best practices.
    * **Strict Merge Rules (Node.js/Express):** When merging Express.js apps, the final code MUST adhere to this template:
        * Include \`helmet({ contentSecurityPolicy: false })\`, \`cors()\`, \`express.json({ limit: "10kb" })\`, \`compression()\`, \`rateLimit(...)\`, and \`morgan("combined")\`.
        * Wrap database connection and \`app.listen()\` inside an \`async startServer()\` function with a \`try/catch\` block.
        * Include a global error handler middleware at the *end* of the stack.
        * Log all errors in structured JSON (level, message, stack, timestamp).
        * Respond with "Internal Server Error" if \`NODE_ENV === "production"\`.
        * Handle graceful shutdown for \`SIGTERM\` and \`SIGINT\`.
        * Use modern JS syntax (\`??\`, optional chaining).

---
### ğŸ“œ 2. Core Rules (How You MUST Behave)

1.  **Language Adaptation (Non-Negotiable)**
    * **If the user message is in Persian (fa):**
        * You MUST respond *entirely* in **Persian (fa)**.
        * This applies to ALL text you generate: explanations, notes, warnings, and all analysis/summaries in compare mode.
        * All Persian text MUST be formatted for **RTL (Right-to-Left)** display to ensure correct rendering.
        * **Crucial:** All technical keywords, code, commands, CLI syntax, file paths, and error names (e.g., \`command not found\`) MUST remain in **English (LTR)**. Do NOT translate code.
    * **If the user message is in English (en):**
        * You MUST respond *entirely* in **English**.
    * You must automatically detect the user's language from their message.

2.  **Output Format (Strict Adherence)**
    * You MUST return responses *only* in the precise format requested by the user's prompt (which is provided by the API backend).
    * **Do NOT** add any conversational fluff, greetings, apologies, or introductory sentences (e.g., "Here is the command you asked for:", "Certainly!", "I hope this helps!").
    * **Be Direct:** Start the response *immediately* with the requested format (e.g., \`command ||| explanation ||| warning\`).
    * **Markdown:** All code, commands, and scripts MUST be inside proper Markdown code blocks (\`\`\`) with the correct language identifier (e.g., \`bash\`, \`javascript\`, \`powershell\`, \`cisco\`).

3.  **Professionalism & Accuracy**
    * Your priority is **Correctness, Safety, and Practicality**.
    * You are an expert. Be confident, direct, and structured.
    * Always prioritize the *most correct and practical* solution for the user's *specific* context (OS, Shell, Device, Knowledge Level).
`;
// -------------------------------------------------------------------------


// Û±. Ú©Ù„Ø§ÛŒÙ†Øª Ø§ØµÙ„ÛŒ (Ø¨Ø±Ø§ÛŒ API Ù¾Ù„ØªÙØ±Ù… Ù¾Ø±Ø§Ù…Ù¾Øª OpenAI)
const openaiClient = new OpenAI({
    apiKey: OPENAI_API_KEY,
    baseURL: OPENAI_API_URL || 'https://api.openai.com/v1',
});

// Û². Ú©Ù„Ø§ÛŒÙ†Øª Ù…Ø­Ù„ÛŒ (Ø¨Ø±Ø§ÛŒ Fallback)
const localClient = new OpenAI({
    apiKey: 'ollama', // Dummy key
    baseURL: AI_LOCAL_MODEL_URL || 'http://localhost:11434/v1',
});

/**
 * ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ API Ø§ØµÙ„ÛŒ (Prompt Platform)
 * Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ø´Ú©Ø³ØªØŒ Fallback Ø¨Ù‡ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ.
 * @param {object} prompt - Ø´ÛŒØ¡ Ù¾Ø±Ø§Ù…Ù¾Øª Ú©Ù„Ø§ÛŒÙ†Øª (Ø­Ø§ÙˆÛŒ prompt.variables).
 * @returns {Promise<string>} Ø®Ø±ÙˆØ¬ÛŒ Ù…ØªÙ†ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² AI.
 */
export const routeRequest = async (prompt) => {

    const allVariables = prompt.variables;

    // --- ØªÙ„Ø§Ø´ Ø§ÙˆÙ„ (Primary): Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² OpenAI Prompt Platform ---
    try {
        console.log(JSON.stringify({
            event: 'ai_route_attempt',
            mode: allVariables.mode,
            engine: 'openai_prompt_platform',
            prompt_id: 'pmpt_68fa6a905dac8195b749aa47ea94d4d8001f6f48395546cd',
            version: '9' // âš ï¸ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ù‡ Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø®ÙˆØ¯ Ø¢Ù¾Ø¯ÛŒØª Ú©Ù†ÛŒØ¯
        }));

        // Ú©Ø¯ Ø¬Ø¯ÛŒØ¯ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ API Ø§ØµÙ„ÛŒ
        const response = await openaiClient.responses.create({
            prompt: {
                "id": "pmpt_68fa6a905dac8195b749aa47ea94d4d8001f6f48395546cd",
                "version": "9", // âš ï¸ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ù‡ Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø®ÙˆØ¯ Ø¢Ù¾Ø¯ÛŒØª Ú©Ù†ÛŒØ¯
                "variables": allVariables // Ø§Ø±Ø³Ø§Ù„ ØªÙ…Ø§Ù… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ
            }
        });

        // ğŸ›‘ Ù†Ø­ÙˆÙ‡ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯
        // Ø§ÛŒÙ† Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø³ØªÙ†Ø¯Ø§Øª OpenAI ÛŒØ§ Ù„Ø§Ú¯ Ù¾Ø§Ø³Ø® ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
        const aiContent = response.text;

        if (!aiContent) {
            throw new Error('OpenAI Prompt Platform returned an empty response.');
        }

        return aiContent; // Ù…ÙˆÙÙ‚ÛŒØª!

    } catch (primaryError) {
        // --- ØªÙ„Ø§Ø´ Ø¯ÙˆÙ… (Fallback): Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ (Ollama) ---
        console.error(JSON.stringify({
            event: 'ai_primary_failed',
            mode: allVariables.mode,
            prompt_id: 'pmpt_... (OpenAI Platform)',
            error: primaryError.message,
        }));

        console.log(JSON.stringify({
            event: 'ai_route_fallback',
            mode: allVariables.mode,
            engine: 'local',
            model: AI_LOCAL_MODEL_NAME,
        }));

        try {
            // Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒØŒ Ø¨Ø§ÛŒØ¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø³ØªÛŒ Ø¨Ø³Ø§Ø²ÛŒÙ…
            // Û±. Ù¾ÛŒØ§Ù… Ø³ÛŒØ³ØªÙ…ÛŒ
            const systemMessage = {
                role: "system",
                content: FINAL_SYSTEM_MESSAGE // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªÙ† Ú©Ø§Ù…Ù„ÛŒ Ú©Ù‡ Ø¯Ø± Ø¨Ø§Ù„Ø§ ØªØ¹Ø±ÛŒÙ Ú©Ø±Ø¯ÛŒÙ…
            };

            // Û². Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± (Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· promptTransformer)
            const userMessages = transformPrompt(allVariables);

            const messages = [
                systemMessage,
                ...userMessages
            ];

            // Û³. ØªÙ…Ø§Ø³ Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ (Ø¨Ø§ API ØµØ­ÛŒØ­)
            const fallbackResponse = await localClient.chat.completions.create({
                model: AI_LOCAL_MODEL_NAME,
                messages: messages, // Ø§Ø±Ø³Ø§Ù„ Ù¾Ø±Ø§Ù…Ù¾Øª Ú©Ø§Ù…Ù„
                stream: false,
                temperature: 0.5,
            });

            const aiContent = fallbackResponse.choices[0].message.content;
            if (!aiContent) {
                throw new Error('Fallback (local) AI returned an empty response.');
            }

            return aiContent; // Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Fallback!

        } catch (fallbackError) {
            // --- Ù‡Ø± Ø¯Ùˆ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù†Ø¯ ---
            console.error(JSON.stringify({
                event: 'ai_fallback_failed',
                mode: allVariables.mode,
                model: AI_LOCAL_MODEL_NAME,
                error: fallbackError.message,
            }));

            // Ù¾Ø±ØªØ§Ø¨ Ø®Ø·Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
            throw new Error(`Both primary (OpenAI Platform) and fallback (Local) services failed. Primary: ${primaryError.message} | Fallback: ${fallbackError.message}`);
        }
    }
};